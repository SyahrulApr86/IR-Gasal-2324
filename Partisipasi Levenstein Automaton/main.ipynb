{"cells":[{"cell_type":"markdown","source":["# Implementasi Levenshtein Automaton untuk Spell Checker"],"metadata":{"collapsed":false,"id":"nlVWL0i5kOC2"}},{"cell_type":"markdown","source":["- Nama: Syahrul Apriansyah\n","- Mata Kuliah: IR Gasal 2023/2024\n","- NPM: 2106708311"],"metadata":{"id":"60TN8eKEkRNL"}},{"cell_type":"markdown","source":["Sebelumnya di kelas kita sudah belajar bagaimana cara kerja dari Demerau Levenshtein Distance. Di bawah ini saya buat implementasinya berdasarkan pseudocode yang ada di slide."],"metadata":{"collapsed":false,"id":"2JqrPGdwkOC4"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"ExecuteTime":{"end_time":"2023-09-26T21:58:22.778553300Z","start_time":"2023-09-26T21:58:22.440329700Z"},"id":"ExibmtggkOC5"},"outputs":[],"source":["def DL_dist(a, b):\n","    # Initialize the wagner-fischer matrix\n","    maxdist = len(a) + len(b)\n","    dist = [[0 for _ in range(len(b) + 2)] for _ in range(len(a) + 2)]\n","\n","    dist[-1][-1] = maxdist\n","    for i in range(len(a) + 1):\n","        dist[i][-1] = maxdist\n","        dist[i][0] = i\n","\n","    for j in range(len(b) + 1):\n","        dist[-1][j] = maxdist\n","        dist[0][j] = j\n","\n","    lastrow = dict()  # A map or dictionary\n","    for i in range(1, len(a) + 1):\n","        lastcol = 0\n","        for j in range(1, len(b) + 1):\n","            lmr = lastrow.get(b[j - 1], 0)\n","            lmc = lastcol\n","\n","            if a[i - 1] == b[j - 1]:\n","                cost = 0\n","                lastcol = j\n","            else:\n","                cost = 1\n","\n","            dist[i][j] = min(\n","                dist[i - 1][j - 1] + cost,\n","                dist[i][j - 1] + 1,\n","                dist[i - 1][j] + 1,\n","                dist[lmr - 1][lmc - 1] + 1 + (i - lmr - 1) + (j - lmc - 1)\n","            )\n","\n","        lastrow[a[i - 1]] = i\n","\n","    return dist[len(a)][len(b)]"]},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":42}],"source":["DL_dist(\"fasasilkom\" , \"fasilkom\")"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T21:58:22.779694800Z","start_time":"2023-09-26T21:58:22.458187200Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"nx4aP8iskOC6","executionInfo":{"status":"ok","timestamp":1695766999513,"user_tz":-420,"elapsed":4,"user":{"displayName":"Error Error","userId":"00908290200837640437"}},"outputId":"6a5923d5-ada2-42aa-d5f1-a444bd7208a3"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40"]},"metadata":{},"execution_count":43}],"source":["DL_dist(\"abcxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxd\",\"abcadasdasdasdxd\")"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T21:58:22.787217200Z","start_time":"2023-09-26T21:58:22.472872Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"T-4C-aOHkOC6","executionInfo":{"status":"ok","timestamp":1695766999514,"user_tz":-420,"elapsed":4,"user":{"displayName":"Error Error","userId":"00908290200837640437"}},"outputId":"7ba87908-c116-4093-f452-874c622d0856"}},{"cell_type":"markdown","source":["Namun di slide juga disebutkan bahwa ada ada cara yang lebih cepat lagi yaitu dengan menggunakan Levenshtein Automata.\n","\n","Di slide diberikan sebuah web sebagai referensi: http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata\n","\n","Pada diperkenalkan pendekatan alternatif: Levenshtein Automata. Pendekatan ini memungkinkan pembuatan automaton yang dapat mengenali string berdasarkan jarak Levenshtein dari kata target. Keuntungannya, automata ini dapat bekerja dalam waktu O(n), lebih cepat dibandingkan dengan algoritma Levenshtein Dynamic Programming yang memerlukan waktu O(mn)."],"metadata":{"collapsed":false,"id":"se8ozGTWkOC6"}},{"cell_type":"markdown","source":["## Levenshtein Automata\n","\n","Levenshtein Automata adalah pendekatan untuk mengenali set kata-kata yang berada dalam jarak Levenshtein tertentu dari kata target. Ini adalah alternatif dari metode tradisional yang menggunakan algoritma Dynamic Programming untuk menghitung jarak Levenshtein, yang memiliki kompleksitas waktu O(mn)."],"metadata":{"collapsed":false,"id":"LY2i94hGkOC7"}},{"cell_type":"markdown","source":["![Levenshtein Automata](http://lh4.ggpht.com/_23zDbjk-dKI/TFAMHm_FQUI/AAAAAAAABrI/jpf9QkVoZUk/levenstein-nfa-food.png)"],"metadata":{"collapsed":false,"id":"ddUSVhUUkOC7"}},{"cell_type":"markdown","source":["**NFA untuk 'food'**:\n","   - Sebagai ilustrasi, sebuah NFA (Non-deterministic Finite Automaton) untuk kata 'food' dengan jarak edit maksimum 2 diperlihatkan. Diagramnya memiliki struktur yang teratur dan mudah dibuat.\n","   - Setiap state dalam NFA diberi label dengan notasi khusus yang menunjukkan jumlah karakter yang telah diproses dan jumlah kesalahan yang ditemukan.\n","   - Ada berbagai jenis transisi antara state: karakter yang tidak diubah, sisipan, penggantian, dan penghapusan."],"metadata":{"collapsed":false,"id":"G5Cc7lN6kOC7"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import bisect\n","\n","class NFA(object):\n","    EPSILON = object()\n","    ANY = object()\n","\n","    def __init__(self, start_state):\n","        self.transitions = {}\n","        self.final_states = set()\n","        self._start_state = start_state\n","\n","    @property\n","    def start_state(self):\n","        return frozenset(self._expand(set([self._start_state])))\n","\n","    def add_transition(self, src, input, dest):\n","        self.transitions.setdefault(src, {}).setdefault(input, set()).add(dest)\n","\n","    def add_final_state(self, state):\n","        self.final_states.add(state)\n","\n","    def is_final(self, states):\n","        return self.final_states.intersection(states)\n","\n","    def _expand(self, states):\n","        frontier = set(states)\n","        while frontier:\n","            state = frontier.pop()\n","            new_states = self.transitions.get(state, {}).get(NFA.EPSILON, set()).difference(states)\n","            frontier.update(new_states)\n","            states.update(new_states)\n","        return states\n","\n","    def next_state(self, states, input):\n","        dest_states = set()\n","        for state in states:\n","            state_transitions = self.transitions.get(state, {})\n","            dest_states.update(state_transitions.get(input, []))\n","            dest_states.update(state_transitions.get(NFA.ANY, []))\n","        return frozenset(self._expand(dest_states))\n","\n","    def get_inputs(self, states):\n","        inputs = set()\n","        for state in states:\n","            inputs.update(self.transitions.get(state, {}).keys())\n","        return inputs\n","\n","    def to_dfa(self):\n","        dfa = DFA(self.start_state)\n","        frontier = [self.start_state]\n","        seen = set()\n","        while frontier:\n","            current = frontier.pop()\n","            inputs = self.get_inputs(current)\n","            for input in inputs:\n","                if input == NFA.EPSILON: continue\n","                new_state = self.next_state(current, input)\n","                if new_state not in seen:\n","                    frontier.append(new_state)\n","                    seen.add(new_state)\n","                    if self.is_final(new_state):\n","                        dfa.add_final_state(new_state)\n","                if input == NFA.ANY:\n","                    dfa.set_default_transition(current, new_state)\n","                else:\n","                    dfa.add_transition(current, input, new_state)\n","        return dfa"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T21:58:22.806914500Z","start_time":"2023-09-26T21:58:22.505626400Z"},"id":"318k9a2SkOC8"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def levenshtein_automata(term, k):\n","    nfa = NFA((0, 0))\n","    for i, c in enumerate(term):\n","        for e in range(k + 1):\n","            # Correct character\n","            nfa.add_transition((i, e), c, (i + 1, e))\n","            if e < k:\n","                # Deletion\n","                nfa.add_transition((i, e), NFA.ANY, (i, e + 1))\n","                # Insertion\n","                nfa.add_transition((i, e), NFA.EPSILON, (i + 1, e + 1))\n","                # Substitution\n","                nfa.add_transition((i, e), NFA.ANY, (i + 1, e + 1))\n","    for e in range(k + 1):\n","        if e < k:\n","            nfa.add_transition((len(term), e), NFA.ANY, (len(term), e + 1))\n","        nfa.add_final_state((len(term), e))\n","    return nfa"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T21:58:22.828452600Z","start_time":"2023-09-26T21:58:22.524450400Z"},"id":"GBn5Vj0AkOC8"}},{"cell_type":"markdown","source":["   - Fungsi Python `levenshtein_automata` diberikan untuk mengkonstruksi NFA ini. Fungsi ini menerima kata dan jarak edit maksimum sebagai input dan mengembalikan NFA yang sesuai.\n","   - Fungsi ini membangun transisi berdasarkan karakter dalam kata dan jarak edit yang diberikan."],"metadata":{"collapsed":false,"id":"u_HYGl4ikOC8"}},{"cell_type":"markdown","source":["**Evaluasi NFA**:\n","   - Meskipun NFA dapat merepresentasikan automata Levenshtein, evaluasi langsung terhadapnya dapat menjadi mahal dari segi komputasi. Hal ini disebabkan oleh keberadaan banyak state aktif dan transisi epsilon (transisi yang tidak memerlukan simbol input).\n","   - Oleh karena itu, praktek standar adalah mengkonversi NFA menjadi DFA (Deterministic Finite Automaton) menggunakan konstruksi powerset.\n","\n","![DFA untuk 'food'](http://lh6.ggpht.com/_23zDbjk-dKI/TFAMHtbPPAI/AAAAAAAABrE/cF_WDpCVCCg/levenstein-dfa-food.png)"],"metadata":{"collapsed":false,"id":"g6fORJKokOC8"}},{"cell_type":"markdown","source":["- DFA untuk kata 'food' dengan satu kesalahan diizinkan diperlihatkan sebagai contoh. DFA ini lebih sederhana daripada NFA yang sesuai dan dapat dengan mudah mengevaluasi apakah kata tertentu berada dalam jarak edit yang diizinkan dari kata target.\n","- DFA ini dapat dibangun dari NFA dengan mengkonstruksi powerset dari state NFA. Setiap state dalam DFA adalah himpunan state NFA yang sesuai.\n","- Meskipun konstruksi NFA dapat dilakukan dalam waktu O(kn), konversi ke DFA memiliki worst case O(2n). Namun, ada optimasi yang telah dikembangkan oleh para peneliti untuk membuat proses ini lebih cepat dan efisien."],"metadata":{"collapsed":false,"id":"DjfGZ4YckOC8"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["class DFA(object):\n","    def __init__(self, start_state):\n","        self.start_state = start_state\n","        self.transitions = {}\n","        self.defaults = {}\n","        self.final_states = set()\n","\n","    def add_transition(self, src, input, dest):\n","        self.transitions.setdefault(src, {})[input] = dest\n","\n","    def set_default_transition(self, src, dest):\n","        self.defaults[src] = dest\n","\n","    def add_final_state(self, state):\n","        self.final_states.add(state)\n","\n","    def is_final(self, state):\n","        return state in self.final_states\n","\n","    def next_state(self, src, input):\n","        state_transitions = self.transitions.get(src, {})\n","        return state_transitions.get(input, self.defaults.get(src, None))\n","\n","    def next_valid_string(self, input):\n","        state = self.start_state\n","        stack = []\n","\n","        # Evaluate the DFA as far as possible\n","        for i, x in enumerate(input):\n","            stack.append((input[:i], state, x))\n","            state = self.next_state(state, x)\n","            if not state: break\n","        else:\n","            stack.append((input[:i+1], state, None))\n","\n","        if self.is_final(state):\n","            # Input word is already valid\n","            return input\n","\n","        # Perform a 'wall following' search for the lexicographically smallest\n","        # accepting state.\n","        while stack:\n","            path, state, x = stack.pop()\n","            x = self.find_next_edge(state, x)\n","            if x:\n","                path += x\n","                state = self.next_state(state, x)\n","                if self.is_final(state):\n","                    return path\n","                stack.append((path, state, None))\n","        return None\n","\n","    def find_next_edge(self, s, x):\n","        if x is None:\n","            x = u'\\0'\n","        else:\n","            x = chr(ord(x) + 1)\n","        state_transitions = self.transitions.get(s, {})\n","        if x in state_transitions or s in self.defaults:\n","            return x\n","        labels = sorted(state_transitions.keys())\n","        pos = bisect.bisect_left(labels, x)\n","        if pos < len(labels):\n","            return labels[pos]\n","        return None"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T21:58:22.846922200Z","start_time":"2023-09-26T21:58:22.546274900Z"},"id":"oGoY1e6EkOC8"}},{"cell_type":"markdown","source":["- Banyak literatur, mencatat bahwa dictionary (yaitu, set dari record yang ingin dicari) dapat direpresentasikan sebagai DFA. Struktur seperti Trie atau DAWG, yang sering digunakan untuk menyimpan kamus, pada dasarnya adalah kasus khusus dari DFA.\n","\n","**Intersect dua DFA**:\n","   - Mengingat dictionary dan kriteria pencarian (Automata Levenshtein) keduanya dapat direpresentasikan sebagai DFA, kita dapat menggabungkan kedua DFA tersebut untuk menemukan kata-kata dalam kamus yang sesuai dengan kriteria kita.\n","   - Fungsi `intersect` diberikan sebagai contoh. Fungsi ini menelusuri kedua DFA secara bersamaan, hanya mengikuti edge yang dimiliki oleh kedua DFA, dan mencatat jalur yang diikuti. Setiap kali kedua DFA berada dalam final state, kata tersebut termasuk dalam output set dan oleh karena itu dihasilkan."],"metadata":{"collapsed":false,"id":"McOJTXB1kOC9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def intersect(dfa1, dfa2):\n","    stack = [(\"\", dfa1.start_state, dfa2.start_state)]\n","    while stack:\n","        s, state1, state2 = stack.pop()\n","        for edge in set(dfa1.edges(state1)).intersect(dfa2.edges(state2)):\n","            state1 = dfa1.next(state1, edge)\n","            state2 = dfa2.next(state2, edge)\n","            if state1 and state2:\n","                s = s + edge\n","                stack.append((s, state1, state2))\n","                if dfa1.is_final(state1) and dfa2.is_final(state2):\n","                    yield s"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T21:58:22.846922200Z","start_time":"2023-09-26T21:58:22.569569700Z"},"id":"FD1GeN7UkOC9"}},{"cell_type":"markdown","source":["**Menghadapi Indeks Non-DFA**:\n","   - Meskipun pendekatan di atas bekerja dengan baik untuk indeks yang disimpan sebagai DFA, banyak indeks yang tidak disimpan dalam format ini. Misalnya, indeks dalam memori mungkin disimpan dalam sorted list, sementara indeks di disk mungkin disimpan dalam struktur seperti BTree.\n","   - Pertanyaannya adalah apakah kita dapat memodifikasi skema ini untuk bekerja dengan jenis indeks ini dan tetap lebih cepat daripada pendekatan brute-force.\n","---\n","\n","- Dengan kriteria pencarian yang dinyatakan sebagai DFA, kita dapat menemukan string berikutnya (dalam urutan leksikografis) yang cocok jika string input tidak cocok.\n","- Intuisinya adalah kita mengevaluasi string input terhadap DFA sampai kita tidak bisa melanjutkan lagi. Kemudian, kita mengikuti edge dengan label leksikografis terkecil hingga kita mencapai keadaan akhir. Ada beberapa kasus khusus yang perlu diperhatikan, seperti saat tidak ada transisi yang valid untuk karakter berikutnya atau saat mencapai keadaan tanpa edge keluar yang valid.\n","- Proses ini mirip dengan algoritma 'wall following', tetapi diterapkan pada DFA."],"metadata":{"collapsed":false,"id":"s8Y4BKqgkOC9"}},{"cell_type":"markdown","source":["**Contoh dengan DFA untuk 'food(1)'**:\n","- Saat mempertimbangkan input 'foogle', kita dapat memproses empat karakter pertama tanpa masalah, tetapi kemudian kita menghadapi masalah dengan karakter 'l'. Kita harus backtrack satu langkah dan mengikuti edge lain untuk mencapai state akhir dengan output string 'fooh', yang merupakan string berikutnya setelah 'foogle' dalam urutan leksikografis."],"metadata":{"collapsed":false,"id":"dOhkC7gjkOC9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["  def next_valid_string(self, input):\n","    state = self.start_state\n","    stack = []\n","\n","    # Evaluate the DFA as far as possible\n","    for i, x in enumerate(input):\n","        stack.append((input[:i], state, x))\n","        state = self.next_state(state, x)\n","        if not state: break\n","    else:\n","        stack.append((input[:i+1], state, None))\n","\n","    if self.is_final(state):\n","        # Input word is already valid\n","        return input\n","\n","    # Perform a 'wall following' search for the lexicographically smallest\n","    # accepting state.\n","    while stack:\n","        path, state, x = stack.pop()\n","        x = self.find_next_edge(state, x)\n","        if x:\n","            path += x\n","            state = self.next_state(state, x)\n","            if self.is_final(state):\n","                return path\n","            stack.append((path, state, None))\n","    return None"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T21:58:22.917380800Z","start_time":"2023-09-26T21:58:22.595522300Z"},"id":"uA8asPL6kOC9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def find_next_edge(self, s, x):\n","    if x is None:\n","        x = u'\\0'\n","    else:\n","        x = chr(ord(x) + 1)\n","    state_transitions = self.transitions.get(s, {})\n","    if x in state_transitions or s in self.defaults:\n","        return x\n","    labels = sorted(state_transitions.keys())\n","    pos = bisect.bisect_left(labels, x)\n","    if pos < len(labels):\n","        return labels[pos]\n","    return None"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T22:04:21.799784100Z","start_time":"2023-09-26T22:04:21.766602300Z"},"id":"wRNvs8aRkOC9"}},{"cell_type":"markdown","source":["- Fungsi `next_valid_string` mengevaluasi DFA sejauh mungkin dengan mempertahankan stack dari state yang dikunjungi. Jika tidak menemukan match yang tepat, fungsi tersebut melakukan backtracking untuk menemukan set transisi terkecil yang dapat diikuti untuk mencapai state akhir.\n","- Fungsi `find_next_edge` menemukan edge keluar leksikografis terkecil dari state yang lebih besar dari input tertentu."],"metadata":{"collapsed":false,"id":"hU-EAZZIkOC9"}},{"cell_type":"markdown","source":["**Optimasi**:\n","   - Dengan beberapa preprocessing, pencarian edge dapat dibuat lebih efisien, misalnya dengan menghasilkan pemetaan dari setiap karakter ke edge keluar pertama yang lebih besar daripadanya.\n","\n","**Algoritma Pencarian Indeks**:\n","   - Dapatkan elemen pertama dari indeks Anda sebagai string 'current'.\n","   - Masukkan string 'current' ke dalam algoritma 'DFA successor' untuk mendapatkan string 'next'.\n","   - Jika 'next' sama dengan 'current', Anda telah menemukan match. Ambil elemen berikutnya dari indeks sebagai string 'current' dan ulangi.\n","   - Jika 'next' tidak sama dengan 'current', cari dalam indeks Anda string yang lebih besar atau sama dengan 'next'. Jadikan ini string 'current' baru dan ulangi."],"metadata":{"collapsed":false,"id":"qN0eL2TjkOC9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def find_all_matches(word, k, lookup_func):\n","    \"\"\"Uses lookup_func to find all words within levenshtein distance k of word.\n","\n","    Args:\n","      word: The word to look up\n","      k: Maximum edit distance\n","      lookup_func: A single argument function that returns the first word in the\n","        database that is greater than or equal to the input argument.\n","    Yields:\n","      Every matching word within levenshtein distance k from the database.\n","    \"\"\"\n","    lev = levenshtein_automata(word, k).to_dfa()\n","    match = lev.next_valid_string(u'\\0')\n","    while match:\n","        next = lookup_func(match)\n","        if not next:\n","            return\n","        if match == next:\n","            yield match\n","            next = next + u'\\0'\n","        match = lev.next_valid_string(next)"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T22:06:01.435640100Z","start_time":"2023-09-26T22:06:01.415417100Z"},"id":"KoKSLdgZkOC-"}},{"cell_type":"markdown","source":["- Fungsi `find_all_matches` menggunakan fungsi pencarian untuk menemukan semua kata dalam jarak Levenshtein k dari kata yang diberikan. Ini menggunakan fungsi `lookup_func` untuk mendapatkan kata berikutnya dari database yang lebih besar atau sama dengan kata yang diberikan.\n","1. **Pandangan Umum**:\n","   - Algoritma ini dapat dilihat sebagai proses yang membandingkan DFA Levenshtein dan indeks sebagai sorted list. Prosedurnya mirip dengan strategi \"zigzag merge join\" dari App Engine. Kita terus-menerus mencari string di satu sisi, lalu menggunakan hasil tersebut untuk melompat ke tempat yang sesuai di sisi lain. Jika tidak ada entri yang cocok, kita menggunakan hasil pencarian untuk melompat lebih jauh di sisi pertama, dan seterusnya. Keuntungan dari pendekatan ini adalah kita dapat melewati banyak entri indeks atau string Levenshtein yang tidak cocok, sehingga menghemat usaha untuk mengenumerasi keduanya secara eksklusif.\n","\n","2. **Efisiensi**:\n","   - Diharapkan dari deskripsi ini, prosedur ini memiliki potensi untuk menghindari kebutuhan untuk mengevaluasi semua entri indeks atau semua string kandidat Levenshtein.\n","\n","3. **Catatan Tambahan**:\n","   - Tidak semua DFA memungkinkan kita untuk menemukan penerus leksikografis minimal untuk setiap string. Sebagai contoh, pertimbangkan penerus string 'a' dalam DFA yang mengenali pola 'a+b'. Tidak ada jawaban yang pasti karena harus terdiri dari jumlah karakter 'a' yang tak terbatas diikuti oleh satu karakter 'b'. Namun, dengan modifikasi sederhana, kita dapat mengembalikan string yang dijamin menjadi awalan dari string berikutnya yang dikenali oleh DFA, yang cukup untuk tujuan kita. Karena DFA Levenshtein selalu terbatas dan selalu memiliki penerus berpanjang finit (kecuali string terakhir), ekstensi seperti itu ditinggalkan sebagai latihan bagi pembaca. Ada potensi aplikasi menarik untuk pendekatan ini, seperti pencarian ekspresi reguler yang diindeks, yang mungkin memerlukan modifikasi ini."],"metadata":{"collapsed":false,"id":"kpTJ3lW6kOC-"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["153\n","3477\n"]}],"source":["import bisect\n","import random\n","\n","\n","class Matcher(object):\n","    def __init__(self, l):\n","        self.l = l\n","        self.probes = 0\n","    def __call__(self, w):\n","        self.probes += 1\n","        pos = bisect.bisect_left(self.l, w)\n","        if pos < len(self.l):\n","            return self.l[pos]\n","        else:\n","            return None\n","\n","\n","words = [x.strip().lower() for x in open('/content/words_alpha.txt', 'r')]\n","words.sort()\n","words10 = [x for x in words if random.random() <= 0.1]\n","words100 = [x for x in words if random.random() <= 0.01]\n","\n","\n","m = Matcher(words)\n","assert len(list(find_all_matches('food', 1, m))) == 21\n","print(m.probes)\n","\n","m = Matcher(words)\n","assert len(list(find_all_matches('food', 2, m))) == 388\n","print(m.probes)\n","\n","\n","def levenshtein(s1, s2):\n","    if len(s1) < len(s2):\n","        return levenshtein(s2, s1)\n","    if not s1:\n","        return len(s2)\n","\n","    previous_row = range(len(s2) + 1)\n","    for i, c1 in enumerate(s1):\n","        current_row = [i + 1]\n","        for j, c2 in enumerate(s2):\n","            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n","            deletions = current_row[j] + 1     # than s2\n","            substitutions = previous_row[j] + (c1 != c2)\n","            current_row.append(min(insertions, deletions, substitutions))\n","        previous_row = current_row\n","\n","    return previous_row[-1]\n","\n","class BKNode(object):\n","    def __init__(self, term):\n","        self.term = term\n","        self.children = {}\n","\n","    def insert(self, other):\n","        distance = levenshtein(self.term, other)\n","        if distance in self.children:\n","            self.children[distance].insert(other)\n","        else:\n","            self.children[distance] = BKNode(other)\n","\n","    def search(self, term, k, results=None):\n","        if results is None:\n","            results = []\n","        distance = levenshtein(self.term, term)\n","        counter = 1\n","        if distance <= k:\n","            results.append(self.term)\n","        for i in range(max(0, distance - k), distance + k + 1):\n","            child = self.children.get(i)\n","            if child:\n","                counter += child.search(term, k, results)\n","        return counter"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T22:15:48.232796300Z","start_time":"2023-09-26T22:15:48.187242100Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"oZN7goaBkOC-","executionInfo":{"status":"ok","timestamp":1695767184446,"user_tz":-420,"elapsed":318,"user":{"displayName":"Error Error","userId":"00908290200837640437"}},"outputId":"c385b273-0e05-485e-8948-a4309cb7a51a"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Words within distance 1 of 'food':\n","['fod', 'foo', 'bood', 'feod', 'fold', 'fond', 'food', 'ford', 'foud', 'good']\n","Number of nodes examined: 3856\n"]}],"source":["# Membangun pohon BK\n","root = BKNode(words[0])\n","for word in words[1:]:\n","    root.insert(word)\n"],"metadata":{"ExecuteTime":{"end_time":"2023-09-26T21:58:22.919380900Z","start_time":"2023-09-26T21:58:22.644823200Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"r-1M1I2bkOC-","executionInfo":{"status":"ok","timestamp":1695767713349,"user_tz":-420,"elapsed":155618,"user":{"displayName":"Error Error","userId":"00908290200837640437"}},"outputId":"d10af37f-3853-4ca1-8e88-d64a2edbcd9a"}},{"cell_type":"code","source":["\n","# Mencari kata dalam pohon BK\n","search_word = \"food\"\n","max_distance = 1\n","results = []\n","num_nodes_examined = root.search(search_word, max_distance, results)\n","print(f\"Words within distance {max_distance} of '{search_word}':\")\n","print(results[:10])\n","print(f\"Number of nodes examined: {num_nodes_examined}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zH1goi3aofd1","executionInfo":{"status":"ok","timestamp":1695767724606,"user_tz":-420,"elapsed":569,"user":{"displayName":"Error Error","userId":"00908290200837640437"}},"outputId":"5ed4a708-ca36-4632-cb1f-f8a441f3d6ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Words within distance 1 of 'food':\n","['fod', 'foo', 'bood', 'feod', 'fold', 'fond', 'food', 'ford', 'foud', 'good']\n","Number of nodes examined: 3856\n"]}]},{"cell_type":"code","source":["search_word = \"food\"\n","max_distance = 2\n","results = []\n","num_nodes_examined = root.search(search_word, max_distance, results)\n","print(f\"Words within distance {max_distance} of '{search_word}':\")\n","print(results[:5])\n","print(f\"Number of nodes examined: {num_nodes_examined}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eNSfhbUnksk","executionInfo":{"status":"ok","timestamp":1695767540580,"user_tz":-420,"elapsed":856,"user":{"displayName":"Error Error","userId":"00908290200837640437"}},"outputId":"dbd855ad-4d57-4366-b986-166ede059ced"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Words within distance 2 of 'food':\n","['fad', 'oad', 'od', 'fo', 'adod']\n","Number of nodes examined: 29825\n"]}]},{"cell_type":"code","source":["search_word = \"food\"\n","max_distance = 4\n","results = []\n","num_nodes_examined = root.search(search_word, max_distance, results)\n","print(f\"Words within distance {max_distance} of '{search_word}':\")\n","print(results[:5])\n","print(f\"Number of nodes examined: {num_nodes_examined}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSEyk6lRnpak","executionInfo":{"status":"ok","timestamp":1695767533022,"user_tz":-420,"elapsed":4019,"user":{"displayName":"Error Error","userId":"00908290200837640437"}},"outputId":"d690d21f-692e-4431-b9b5-73fb7f740731"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Words within distance 4 of 'food':\n","['a', 'aa', 'ab', 'ac', 'ad']\n","Number of nodes examined: 150010\n"]}]},{"cell_type":"markdown","source":["actual code: https://gist.github.com/Arachnid/491973\n","dictionary: https://github.com/dwyl/english-words/blob/master/words_alpha.txt"],"metadata":{"id":"m5umED8cpAbV"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}